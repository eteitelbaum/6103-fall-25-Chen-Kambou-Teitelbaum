{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e4a177",
   "metadata": {},
   "source": [
    "# FLFP Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c09b38",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cd1028e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For data splitting and preprocessing\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For modeling and evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8b092",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03607580",
   "metadata": {},
   "source": [
    "### Load the FLFP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "122bad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5208 entries, 0 to 5207\n",
      "Data columns (total 25 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   country_name             5208 non-null   object \n",
      " 1   flfp_15_64               4484 non-null   float64\n",
      " 2   year                     5208 non-null   int64  \n",
      " 3   fertility_rate           5208 non-null   float64\n",
      " 4   fertility_adolescent     5208 non-null   float64\n",
      " 5   urban_population         5160 non-null   float64\n",
      " 6   dependency_ratio         5208 non-null   float64\n",
      " 7   life_exp_female          5208 non-null   float64\n",
      " 8   infant_mortality         4704 non-null   float64\n",
      " 9   population_total         5208 non-null   float64\n",
      " 10  secondary_enroll_fe      3427 non-null   float64\n",
      " 11  tertiary_enroll_fe       2979 non-null   float64\n",
      " 12  gender_parity_primary    2874 non-null   float64\n",
      " 13  gender_parity_secondary  2934 non-null   float64\n",
      " 14  gdp_per_capita_const     4935 non-null   float64\n",
      " 15  gdp_growth               4957 non-null   float64\n",
      " 16  services_gdp             4635 non-null   float64\n",
      " 17  industry_gdp             4684 non-null   float64\n",
      " 18  rule_of_law              4683 non-null   float64\n",
      " 19  unemployment_total       4484 non-null   float64\n",
      " 20  unemployment_female      4484 non-null   float64\n",
      " 21  labor_force_total        4484 non-null   float64\n",
      " 22  iso3c                    5208 non-null   object \n",
      " 23  region                   5208 non-null   object \n",
      " 24  income_level             5208 non-null   object \n",
      "dtypes: float64(20), int64(1), object(4)\n",
      "memory usage: 1017.3+ KB\n"
     ]
    }
   ],
   "source": [
    "flfp_df = pd.read_parquet('data/flfp_dataset.parquet')\n",
    "flfp_df['region'] = flfp_df['region'].str.strip()  # Clean trailing spaces\n",
    "flfp_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d365dac",
   "metadata": {},
   "source": [
    "### Perform train-test split\n",
    "With this being panel data, we have to be careful not to leak future data for any country into the training set. We could try a time-base split, but time-series forecasting is not necessarily our goal here. Instead, we'll do a country-based split, ensuring that all years for a given country are either in the training or test set.\n",
    "\n",
    "**Note on stratification**: We initially attempted to stratify the split by region or income level to ensure balanced representation across splits. However, this approach did not improve model performance and in some cases led to worse validation metrics, likely due to the relatively small number of countries per category creating unlucky splits. We therefore use a simple random split with a fixed seed for reproducibility, which empirically produces reasonable balance across most key dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cd525abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country-based Train/Validation/Test Split\n",
      "==================================================\n",
      "Total observations: 4,484\n",
      "Unique countries: 187\n",
      "Obs per country - Min: 22, Max: 24, Mean: 24.0\n",
      "\n",
      "Countries in training set: 112 (59.9%)\n",
      "Countries in validation set: 37 (19.8%)\n",
      "Countries in test set: 38 (20.3%)\n",
      "\n",
      "Training observations: 2,685 (59.9%)\n",
      "Validation observations: 888 (19.8%)\n",
      "Test observations: 911 (20.3%)\n",
      "\n",
      "✓ Verified: No countries appear in multiple sets\n",
      "\n",
      "Sample training countries: ['India', 'Nicaragua', 'Lesotho', 'Cameroon', 'New Caledonia']\n",
      "Sample validation countries: ['Kuwait', 'Gabon', 'Burundi']\n",
      "Sample test countries: ['Dominican Republic', 'Virgin Islands (U.S.)', 'Kenya']\n"
     ]
    }
   ],
   "source": [
    "# Filter to FLFP observations\n",
    "modeling_df = flfp_df[flfp_df['flfp_15_64'].notna()].copy()\n",
    "\n",
    "print(\"Country-based Train/Validation/Test Split\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get unique countries and their observation counts\n",
    "country_stats = modeling_df.groupby('country_name').size().reset_index(name='obs_count')\n",
    "country_stats = country_stats.sort_values('obs_count', ascending=False)\n",
    "\n",
    "print(f\"Total observations: {len(modeling_df):,}\")\n",
    "print(f\"Unique countries: {len(country_stats)}\")\n",
    "print(f\"Obs per country - Min: {country_stats['obs_count'].min()}, Max: {country_stats['obs_count'].max()}, Mean: {country_stats['obs_count'].mean():.1f}\")\n",
    "\n",
    "# Step 1: Split countries into train (60%) and temp (40%)\n",
    "# (Crucially, we are splitting country names into sets, not individual observations)\n",
    "countries_train, countries_temp = train_test_split(\n",
    "    country_stats['country_name'].tolist(),\n",
    "    test_size=0.4,  # 40% for val + test\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Split temp into validation (20%) and test (20%)\n",
    "countries_val, countries_test = train_test_split(\n",
    "    countries_temp,\n",
    "    test_size=0.5,  # 50% of 40% = 20% overall\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nCountries in training set: {len(countries_train)} ({len(countries_train)/len(country_stats)*100:.1f}%)\")\n",
    "print(f\"Countries in validation set: {len(countries_val)} ({len(countries_val)/len(country_stats)*100:.1f}%)\")\n",
    "print(f\"Countries in test set: {len(countries_test)} ({len(countries_test)/len(country_stats)*100:.1f}%)\")\n",
    "\n",
    "# Create train/val/test datasets based on country assignment\n",
    "# (Here we are creating boolean masks to identify which observations belong to which set)\n",
    "train_mask = modeling_df['country_name'].isin(countries_train)\n",
    "val_mask = modeling_df['country_name'].isin(countries_val)\n",
    "test_mask = modeling_df['country_name'].isin(countries_test)\n",
    "\n",
    "# Subset the main dataframe\n",
    "train_df = modeling_df[train_mask].copy()\n",
    "val_df = modeling_df[val_mask].copy()\n",
    "test_df = modeling_df[test_mask].copy()\n",
    "\n",
    "print(f\"\\nTraining observations: {len(train_df):,} ({len(train_df)/len(modeling_df)*100:.1f}%)\")\n",
    "print(f\"Validation observations: {len(val_df):,} ({len(val_df)/len(modeling_df)*100:.1f}%)\")\n",
    "print(f\"Test observations: {len(test_df):,} ({len(test_df)/len(modeling_df)*100:.1f}%)\")\n",
    "\n",
    "# Verify no country overlap\n",
    "train_countries_set = set(train_df['country_name'])\n",
    "val_countries_set = set(val_df['country_name'])\n",
    "test_countries_set = set(test_df['country_name'])\n",
    "\n",
    "assert len(train_countries_set & val_countries_set) == 0, \"Train/Val country overlap detected!\"\n",
    "assert len(train_countries_set & test_countries_set) == 0, \"Train/Test country overlap detected!\"\n",
    "assert len(val_countries_set & test_countries_set) == 0, \"Val/Test country overlap detected!\"\n",
    "\n",
    "print(\"\\n✓ Verified: No countries appear in multiple sets\")\n",
    "\n",
    "# Preview country assignments\n",
    "print(f\"\\nSample training countries: {countries_train[:5]}\")\n",
    "print(f\"Sample validation countries: {countries_val[:3]}\")\n",
    "print(f\"Sample test countries: {countries_test[:3]}\")\n",
    "\n",
    "# Store the split for later use\n",
    "country_split = {\n",
    "    'train_countries': countries_train,\n",
    "    'val_countries': countries_val, \n",
    "    'test_countries': countries_test,\n",
    "    'train_df': train_df,\n",
    "    'val_df': val_df,\n",
    "    'test_df': test_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b523301",
   "metadata": {},
   "source": [
    "### Add categorical features (region and income level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "836a9af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out 'Not classified' income observations...\n",
      "  Train: 2685 → 2661 (-24)\n",
      "  Val: 888 → 888 (-0)\n",
      "  Test: 911 → 887 (-24)\n",
      "\n",
      "Creating label-encoded income (for tree-based models)...\n",
      "  Income encoding: {'Low income': 0, 'Lower middle income': 1, 'Upper middle income': 2, 'High income': 3}\n",
      "\n",
      "Creating one-hot encoded region with clean names...\n",
      "  Created 6 region dummy variables\n",
      "  Reference category: region_mena_afpak (dropped)\n",
      "  Region columns: ['region_eap', 'region_eca', 'region_lac', 'region_namerica', 'region_sasia', 'region_ssa']\n",
      "\n",
      "Creating one-hot encoded income with clean names (for linear models)...\n",
      "  Created 3 income dummy variables\n",
      "  Reference category: income_low (dropped)\n",
      "  Income columns: ['income_high', 'income_lower_mid', 'income_upper_mid']\n",
      "\n",
      "✓ Categorical features added successfully!\n",
      "  Train shape: (2661, 35)\n",
      "  Val shape: (888, 35)\n",
      "  Test shape: (887, 35)\n"
     ]
    }
   ],
   "source": [
    "# Filter out 'Not classified' income observations\n",
    "print(\"Filtering out 'Not classified' income observations...\")\n",
    "initial_train = len(train_df)\n",
    "initial_val = len(val_df)\n",
    "initial_test = len(test_df)\n",
    "\n",
    "train_df = train_df[train_df['income_level'] != 'Not classified'].copy()\n",
    "val_df = val_df[val_df['income_level'] != 'Not classified'].copy()\n",
    "test_df = test_df[test_df['income_level'] != 'Not classified'].copy()\n",
    "\n",
    "print(f\"  Train: {initial_train} → {len(train_df)} (-{initial_train - len(train_df)})\")\n",
    "print(f\"  Val: {initial_val} → {len(val_df)} (-{initial_val - len(val_df)})\")\n",
    "print(f\"  Test: {initial_test} → {len(test_df)} (-{initial_test - len(test_df)})\")\n",
    "\n",
    "# Create label-encoded income for tree-based models\n",
    "print(\"\\nCreating label-encoded income (for tree-based models)...\")\n",
    "income_mapping = {\n",
    "    'Low income': 0,\n",
    "    'Lower middle income': 1,\n",
    "    'Upper middle income': 2,\n",
    "    'High income': 3\n",
    "}\n",
    "\n",
    "train_df['income_level_encoded'] = train_df['income_level'].map(income_mapping)\n",
    "val_df['income_level_encoded'] = val_df['income_level'].map(income_mapping)\n",
    "test_df['income_level_encoded'] = test_df['income_level'].map(income_mapping)\n",
    "\n",
    "print(f\"  Income encoding: {income_mapping}\")\n",
    "\n",
    "# Create one-hot encoded region with clean names\n",
    "print(\"\\nCreating one-hot encoded region with clean names...\")\n",
    "\n",
    "# Region name mapping to clean snake_case abbreviations\n",
    "region_name_mapping = {\n",
    "    'East Asia & Pacific': 'region_eap',\n",
    "    'Europe & Central Asia': 'region_eca',\n",
    "    'Latin America & Caribbean': 'region_lac',\n",
    "    'Middle East, North Africa, Afghanistan & Pakistan': 'region_mena_afpak',\n",
    "    'North America': 'region_namerica',\n",
    "    'South Asia': 'region_sasia',\n",
    "    'Sub-Saharan Africa': 'region_ssa'\n",
    "}\n",
    "\n",
    "# Create dummies for ALL regions (drop_first=False to get all categories)\n",
    "region_dummies_train = pd.get_dummies(train_df['region'], prefix='region', drop_first=False)\n",
    "region_dummies_val = pd.get_dummies(val_df['region'], prefix='region', drop_first=False)\n",
    "region_dummies_test = pd.get_dummies(test_df['region'], prefix='region', drop_first=False)\n",
    "\n",
    "# Rename columns using mapping\n",
    "for original, clean in region_name_mapping.items():\n",
    "    old_col = f'region_{original}'\n",
    "    if old_col in region_dummies_train.columns:\n",
    "        region_dummies_train.rename(columns={old_col: clean}, inplace=True)\n",
    "    if old_col in region_dummies_val.columns:\n",
    "        region_dummies_val.rename(columns={old_col: clean}, inplace=True)\n",
    "    if old_col in region_dummies_test.columns:\n",
    "        region_dummies_test.rename(columns={old_col: clean}, inplace=True)\n",
    "\n",
    "# Drop reference category: region_mena_afpak\n",
    "reference_region = 'region_mena_afpak'\n",
    "if reference_region in region_dummies_train.columns:\n",
    "    region_dummies_train.drop(columns=[reference_region], inplace=True)\n",
    "if reference_region in region_dummies_val.columns:\n",
    "    region_dummies_val.drop(columns=[reference_region], inplace=True)\n",
    "if reference_region in region_dummies_test.columns:\n",
    "    region_dummies_test.drop(columns=[reference_region], inplace=True)\n",
    "\n",
    "# Ensure all sets have the same columns (in case some regions are missing in val/test)\n",
    "all_region_cols = region_dummies_train.columns.tolist()\n",
    "for col in all_region_cols:\n",
    "    if col not in region_dummies_val.columns:\n",
    "        region_dummies_val[col] = 0\n",
    "    if col not in region_dummies_test.columns:\n",
    "        region_dummies_test[col] = 0\n",
    "\n",
    "# Reorder columns to match\n",
    "region_dummies_val = region_dummies_val[all_region_cols]\n",
    "region_dummies_test = region_dummies_test[all_region_cols]\n",
    "\n",
    "# Add to dataframes\n",
    "train_df = pd.concat([train_df, region_dummies_train], axis=1)\n",
    "val_df = pd.concat([val_df, region_dummies_val], axis=1)\n",
    "test_df = pd.concat([test_df, region_dummies_test], axis=1)\n",
    "\n",
    "print(f\"  Created {len(all_region_cols)} region dummy variables\")\n",
    "print(f\"  Reference category: {reference_region} (dropped)\")\n",
    "print(f\"  Region columns: {all_region_cols}\")\n",
    "\n",
    "# Create one-hot encoded income with clean names (for linear models)\n",
    "print(\"\\nCreating one-hot encoded income with clean names (for linear models)...\")\n",
    "\n",
    "# Income level name mapping to clean snake_case abbreviations\n",
    "income_name_mapping = {\n",
    "    'High income': 'income_high',\n",
    "    'Low income': 'income_low',\n",
    "    'Lower middle income': 'income_lower_mid',\n",
    "    'Upper middle income': 'income_upper_mid'\n",
    "}\n",
    "\n",
    "# Create dummies for ALL income levels (drop_first=False to get all categories)\n",
    "income_dummies_train = pd.get_dummies(train_df['income_level'], prefix='income', drop_first=False)\n",
    "income_dummies_val = pd.get_dummies(val_df['income_level'], prefix='income', drop_first=False)\n",
    "income_dummies_test = pd.get_dummies(test_df['income_level'], prefix='income', drop_first=False)\n",
    "\n",
    "# Rename columns using mapping\n",
    "for original, clean in income_name_mapping.items():\n",
    "    old_col = f'income_{original}'\n",
    "    if old_col in income_dummies_train.columns:\n",
    "        income_dummies_train.rename(columns={old_col: clean}, inplace=True)\n",
    "    if old_col in income_dummies_val.columns:\n",
    "        income_dummies_val.rename(columns={old_col: clean}, inplace=True)\n",
    "    if old_col in income_dummies_test.columns:\n",
    "        income_dummies_test.rename(columns={old_col: clean}, inplace=True)\n",
    "\n",
    "# Drop reference category: income_low\n",
    "reference_income = 'income_low'\n",
    "if reference_income in income_dummies_train.columns:\n",
    "    income_dummies_train.drop(columns=[reference_income], inplace=True)\n",
    "if reference_income in income_dummies_val.columns:\n",
    "    income_dummies_val.drop(columns=[reference_income], inplace=True)\n",
    "if reference_income in income_dummies_test.columns:\n",
    "    income_dummies_test.drop(columns=[reference_income], inplace=True)\n",
    "\n",
    "# Ensure all sets have the same columns\n",
    "all_income_cols = income_dummies_train.columns.tolist()\n",
    "for col in all_income_cols:\n",
    "    if col not in income_dummies_val.columns:\n",
    "        income_dummies_val[col] = 0\n",
    "    if col not in income_dummies_test.columns:\n",
    "        income_dummies_test[col] = 0\n",
    "\n",
    "# Reorder columns to match\n",
    "income_dummies_val = income_dummies_val[all_income_cols]\n",
    "income_dummies_test = income_dummies_test[all_income_cols]\n",
    "\n",
    "# Add to dataframes\n",
    "train_df = pd.concat([train_df, income_dummies_train], axis=1)\n",
    "val_df = pd.concat([val_df, income_dummies_val], axis=1)\n",
    "test_df = pd.concat([test_df, income_dummies_test], axis=1)\n",
    "\n",
    "print(f\"  Created {len(all_income_cols)} income dummy variables\")\n",
    "print(f\"  Reference category: {reference_income} (dropped)\")\n",
    "print(f\"  Income columns: {all_income_cols}\")\n",
    "\n",
    "print(\"\\n✓ Categorical features added successfully!\")\n",
    "print(f\"  Train shape: {train_df.shape}\")\n",
    "print(f\"  Val shape: {val_df.shape}\")\n",
    "print(f\"  Test shape: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db53ea",
   "metadata": {},
   "source": [
    "### Preprocess the data\n",
    "We need three datasets for different model types: raw data for tree-based models for XGBoost and LightGBM, imputed but unscaled for random forest, and imputed and scaled for linear models, SVM and KNN. \n",
    "\n",
    "For imputation, we will take the country median as the default strategy but if the country has all missing values for a feature, we will use the global mean instead.\n",
    "\n",
    "For scaling, we will use standard scaling (mean=0, std=1) based on the training set statistics.\n",
    "\n",
    "Note that we are conducting the imputation and scaling after splitting to avoid data leakage (in other words, using information from the test set to inform the training set transformations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "932682e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor Column Setup:\n",
      "  Base numeric features: 13\n",
      "  Region dummies: 6\n",
      "  Income dummies: 3\n",
      "  Total for tree models: 20 (base + income_encoded + regions)\n",
      "  Total for linear models: 22 (base + income_dummies + regions)\n",
      "\n",
      "Applying log transformation to population_total (before extraction)...\n",
      "  ✓ Log transformation applied to raw data\n",
      "\n",
      "Dataset 1 - Truly Raw/Unimputed (XGBoost, LightGBM):\n",
      "  Using predictor_cols_tree (20 features)\n",
      "  X_train_raw: (2661, 20)\n",
      "  X_val_raw: (888, 20)\n",
      "  X_test_raw: (887, 20)\n",
      "  Missing values - Train: 1903\n",
      "  Missing values - Val: 368\n",
      "  Missing values - Test: 329\n",
      "\n",
      "Imputation complete:\n",
      "Dataset 2 - Imputed (Random Forest):\n",
      "  Using predictor_cols_tree (20 features)\n",
      "  X_train_imputed: (2661, 20)\n",
      "  X_val_imputed: (888, 20)\n",
      "  X_test_imputed: (887, 20)\n",
      "  Missing values - Train: 0\n",
      "  Missing values - Val: 0\n",
      "  Missing values - Test: 0\n",
      "\n",
      "Creating scaled datasets...\n",
      "\n",
      "Dataset 3 - Scaled + Imputed (Linear models, SVM, KNN):\n",
      "  Using predictor_cols_linear (22 features)\n",
      "  X_train_scaled: (2661, 22)\n",
      "  X_val_scaled: (888, 22)\n",
      "  X_test_scaled: (887, 22)\n",
      "\n",
      "Target variable (same for all models):\n",
      "  y_train: (2661,)\n",
      "  y_val: (888,)\n",
      "  y_test: (887,)\n",
      "\n",
      "Setting up GroupKFold cross-validation...\n",
      "  Using GroupKFold with 5 splits grouped by country\n",
      "  This prevents different years from the same country appearing in different folds\n",
      "\n",
      "✓ All datasets ready for modeling!\n",
      "Tree models: 20 features (numeric + income_encoded + region_dummies)\n",
      "Linear models: 22 features (numeric + income_dummies + region_dummies)\n",
      "Total observations: 4,436\n"
     ]
    }
   ],
   "source": [
    "# Define base predictor columns (numeric features)\n",
    "# Note: Removed unemployment_total, unemployment_female, and labor_force_total\n",
    "# to avoid data leakage (these are mathematically related to FLFP)\n",
    "base_predictor_cols = [\n",
    "    'fertility_rate', 'fertility_adolescent', 'urban_population',\n",
    "    'dependency_ratio', 'life_exp_female', 'infant_mortality',\n",
    "    'population_total', 'secondary_enroll_fe', 'gdp_per_capita_const',\n",
    "    'gdp_growth', 'services_gdp', 'industry_gdp', 'rule_of_law'\n",
    " ]\n",
    "\n",
    "# Get the categorical feature column names that were created in the previous cell\n",
    "region_cols = [col for col in train_df.columns if col.startswith('region_')]\n",
    "# Get income dummy columns (exclude 'income_level' and 'income_level_encoded')\n",
    "income_dummy_cols = [col for col in train_df.columns if col.startswith('income_') and col not in ['income_level', 'income_level_encoded']]\n",
    "\n",
    "# Create separate predictor lists for different model types\n",
    "# Tree-based models: use label-encoded income + one-hot region\n",
    "predictor_cols_tree = base_predictor_cols + ['income_level_encoded'] + region_cols\n",
    "\n",
    "# Linear models: use one-hot encoded income + one-hot region\n",
    "predictor_cols_linear = base_predictor_cols + income_dummy_cols + region_cols\n",
    "\n",
    "print(\"Predictor Column Setup:\")\n",
    "print(f\"  Base numeric features: {len(base_predictor_cols)}\")\n",
    "print(f\"  Region dummies: {len(region_cols)}\")\n",
    "print(f\"  Income dummies: {len(income_dummy_cols)}\")\n",
    "print(f\"  Total for tree models: {len(predictor_cols_tree)} (base + income_encoded + regions)\")\n",
    "print(f\"  Total for linear models: {len(predictor_cols_linear)} (base + income_dummies + regions)\")\n",
    "\n",
    "target_col = 'flfp_15_64'\n",
    "\n",
    "# Variables that need imputation (only numeric features need imputation)\n",
    "variables_to_impute = [\n",
    "    'secondary_enroll_fe', 'urban_population', 'infant_mortality',\n",
    "    'gdp_per_capita_const', 'gdp_growth', 'services_gdp',\n",
    "    'industry_gdp', 'rule_of_law'\n",
    " ]\n",
    "\n",
    "def panel_imputation(train_df, val_df, test_df, variables_to_impute):\n",
    "    \"\"\"Apply country-specific median imputation without data leakage\"\"\"\n",
    "\n",
    "    # Calculate imputation rules using ONLY training data\n",
    "    train_country_medians = {}\n",
    "    train_year_medians = {}\n",
    "    train_global_medians = {}\n",
    "\n",
    "    for var in variables_to_impute:\n",
    "        # Country-specific medians from training data only\n",
    "        train_country_medians[var] = train_df.groupby('country_name')[var].median()\n",
    "        # Year-specific medians from training data only\n",
    "        train_year_medians[var] = train_df.groupby('year')[var].median()\n",
    "        # Global median from training data only\n",
    "        train_global_medians[var] = train_df[var].median()\n",
    "\n",
    "    # Apply imputation rules to all datasets\n",
    "    def apply_imputation(df):\n",
    "        df_imputed = df.copy()\n",
    "        for var in variables_to_impute:\n",
    "            if var in df_imputed.columns:\n",
    "                # Use training-based country medians\n",
    "                for country in df_imputed['country_name'].unique():\n",
    "                    country_mask = df_imputed['country_name'] == country\n",
    "                    country_median = train_country_medians[var].get(country, np.nan)\n",
    "\n",
    "                    # Fill using country median where available\n",
    "                    df_imputed.loc[country_mask, var] = df_imputed.loc[country_mask, var].fillna(country_median)\n",
    "\n",
    "                # Fill remaining NaNs using year medians\n",
    "                year_values = df_imputed.loc[:, 'year']\n",
    "                missing_mask = df_imputed[var].isna()\n",
    "                if missing_mask.any():\n",
    "                    years_to_fill = year_values[missing_mask]\n",
    "                    fill_values = years_to_fill.map(train_year_medians[var]).astype(float)\n",
    "                    df_imputed.loc[missing_mask, var] = fill_values\n",
    "\n",
    "                # Fall back to training-global median if still missing\n",
    "                df_imputed[var] = df_imputed[var].fillna(train_global_medians[var])\n",
    "\n",
    "        return df_imputed\n",
    "\n",
    "    return apply_imputation(train_df), apply_imputation(val_df), apply_imputation(test_df)\n",
    "\n",
    "# Log-transform population_total in the original dataframes (before imputation)\n",
    "# This will affect both raw and imputed datasets\n",
    "print(\"\\nApplying log transformation to population_total (before extraction)...\")\n",
    "train_df['population_total'] = np.log(train_df['population_total'])\n",
    "val_df['population_total'] = np.log(val_df['population_total'])\n",
    "test_df['population_total'] = np.log(test_df['population_total'])\n",
    "print(\"  ✓ Log transformation applied to raw data\")\n",
    "\n",
    "# Extract TRULY raw features (before imputation) for models that handle missing values natively\n",
    "# Use tree predictor columns (includes income_level_encoded + region dummies)\n",
    "X_train_raw = train_df[predictor_cols_tree].copy()\n",
    "X_val_raw = val_df[predictor_cols_tree].copy()\n",
    "X_test_raw = test_df[predictor_cols_tree].copy()\n",
    "\n",
    "print(\"\\nDataset 1 - Truly Raw/Unimputed (XGBoost, LightGBM):\")\n",
    "print(f\"  Using predictor_cols_tree ({len(predictor_cols_tree)} features)\")\n",
    "print(f\"  X_train_raw: {X_train_raw.shape}\")\n",
    "print(f\"  X_val_raw: {X_val_raw.shape}\")\n",
    "print(f\"  X_test_raw: {X_test_raw.shape}\")\n",
    "print(f\"  Missing values - Train: {X_train_raw.isna().sum().sum()}\")\n",
    "print(f\"  Missing values - Val: {X_val_raw.isna().sum().sum()}\")\n",
    "print(f\"  Missing values - Test: {X_test_raw.isna().sum().sum()}\")\n",
    "\n",
    "# Apply imputation\n",
    "train_clean, val_clean, test_clean = panel_imputation(\n",
    "    train_df, val_df, test_df, variables_to_impute\n",
    ")\n",
    "\n",
    "# Extract imputed features and target\n",
    "# Use tree predictor columns (includes income_level_encoded + region dummies)\n",
    "X_train_imputed = train_clean[predictor_cols_tree].copy()\n",
    "X_val_imputed = val_clean[predictor_cols_tree].copy()\n",
    "X_test_imputed = test_clean[predictor_cols_tree].copy()\n",
    "\n",
    "y_train = train_clean[target_col].copy()\n",
    "y_val = val_clean[target_col].copy()\n",
    "y_test = test_clean[target_col].copy()\n",
    "\n",
    "print(\"\\nImputation complete:\")\n",
    "print(\"Dataset 2 - Imputed (Random Forest):\")\n",
    "print(f\"  Using predictor_cols_tree ({len(predictor_cols_tree)} features)\")\n",
    "print(f\"  X_train_imputed: {X_train_imputed.shape}\")\n",
    "print(f\"  X_val_imputed: {X_val_imputed.shape}\")\n",
    "print(f\"  X_test_imputed: {X_test_imputed.shape}\")\n",
    "print(f\"  Missing values - Train: {X_train_imputed.isna().sum().sum()}\")\n",
    "print(f\"  Missing values - Val: {X_val_imputed.isna().sum().sum()}\")\n",
    "print(f\"  Missing values - Test: {X_test_imputed.isna().sum().sum()}\")\n",
    "\n",
    "# Create scaled versions (fit scaler only on training data)\n",
    "# Use linear predictor columns (includes income dummies + region dummies)\n",
    "print(\"\\nCreating scaled datasets...\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Need to extract linear predictor columns from the clean dataframes\n",
    "X_train_linear = train_clean[predictor_cols_linear].copy()\n",
    "X_val_linear = val_clean[predictor_cols_linear].copy()\n",
    "X_test_linear = test_clean[predictor_cols_linear].copy()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train_linear),\n",
    "    columns=predictor_cols_linear,\n",
    "    index=X_train_linear.index\n",
    ")\n",
    "X_val_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_val_linear),\n",
    "    columns=predictor_cols_linear,\n",
    "    index=X_val_linear.index\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test_linear),\n",
    "    columns=predictor_cols_linear,\n",
    "    index=X_test_linear.index\n",
    ")\n",
    "\n",
    "print(\"\\nDataset 3 - Scaled + Imputed (Linear models, SVM, KNN):\")\n",
    "print(f\"  Using predictor_cols_linear ({len(predictor_cols_linear)} features)\")\n",
    "print(f\"  X_train_scaled: {X_train_scaled.shape}\")\n",
    "print(f\"  X_val_scaled: {X_val_scaled.shape}\")\n",
    "print(f\"  X_test_scaled: {X_test_scaled.shape}\")\n",
    "\n",
    "print(\"\\nTarget variable (same for all models):\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  y_val: {y_val.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")\n",
    "\n",
    "# Create GroupKFold for hyperparameter tuning to prevent data leakage\n",
    "# This ensures all observations from the same country stay in the same fold\n",
    "print(\"\\nSetting up GroupKFold cross-validation...\")\n",
    "groups_train = train_clean['country_name'].values\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "print(f\"  Using GroupKFold with 5 splits grouped by country\")\n",
    "print(f\"  This prevents different years from the same country appearing in different folds\")\n",
    "\n",
    "print(\"\\n✓ All datasets ready for modeling!\")\n",
    "print(f\"Tree models: {len(predictor_cols_tree)} features (numeric + income_encoded + region_dummies)\")\n",
    "print(f\"Linear models: {len(predictor_cols_linear)} features (numeric + income_dummies + region_dummies)\")\n",
    "print(f\"Total observations: {len(X_train_raw) + len(X_val_raw) + len(X_test_raw):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1633b80",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef65c12",
   "metadata": {},
   "source": [
    "### Simple OLS (no regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6dc83b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Performance:\n",
      "  RMSE: 11.005\n",
      "  MAE:  8.400\n",
      "  R²:   0.531\n",
      "\n",
      "Validation Performance:\n",
      "  RMSE: 12.045\n",
      "  MAE:  9.660\n",
      "  R²:   0.462\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                 feature  importance\n",
      "17            region_eca   13.607349\n",
      "16            region_eap   12.771008\n",
      "21            region_ssa   11.205452\n",
      "18            region_lac    9.671223\n",
      "4        life_exp_female    8.629168\n",
      "13           income_high    8.126479\n",
      "3       dependency_ratio    7.568505\n",
      "15      income_upper_mid    7.103070\n",
      "1   fertility_adolescent    6.010921\n",
      "8   gdp_per_capita_const    5.693085\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "ols_model = LinearRegression()\n",
    "\n",
    "# Fit on training data (using scaled data for linear models)\n",
    "ols_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on train and validation sets\n",
    "y_train_pred = ols_model.predict(X_train_scaled)\n",
    "y_val_pred = ols_model.predict(X_val_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: {train_rmse:.3f}\")\n",
    "print(f\"  MAE:  {train_mae:.3f}\")\n",
    "print(f\"  R²:   {train_r2:.3f}\")\n",
    "\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  RMSE: {val_rmse:.3f}\")\n",
    "print(f\"  MAE:  {val_mae:.3f}\")\n",
    "print(f\"  R²:   {val_r2:.3f}\")\n",
    "\n",
    "# Feature importance for OLS (coefficient magnitudes)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': predictor_cols_linear,\n",
    "    'importance': np.abs(ols_model.coef_)\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0290840",
   "metadata": {},
   "source": [
    "### Lasso Regression (L1 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2fc11b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (regularization strength): 0.1\n",
      "Cross-validation score: 190.936\n",
      "\n",
      "Training Performance:\n",
      "  RMSE: 11.080\n",
      "  MAE:  8.426\n",
      "  R²:   0.525\n",
      "\n",
      "Validation Performance:\n",
      "  RMSE: 11.818\n",
      "  MAE:  9.355\n",
      "  R²:   0.482\n",
      "\n",
      "Feature Selection:\n",
      "  Features selected: 20/22\n",
      "  Features eliminated: 2\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                feature  importance\n",
      "0        fertility_rate    0.000000\n",
      "1  fertility_adolescent    5.113766\n",
      "2      urban_population    2.012054\n",
      "3      dependency_ratio    6.478956\n",
      "4       life_exp_female    6.474594\n",
      "5      infant_mortality    2.404265\n",
      "6      population_total    0.298316\n",
      "7   secondary_enroll_fe    0.822782\n",
      "8  gdp_per_capita_const    4.968650\n",
      "9            gdp_growth    0.093619\n"
     ]
    }
   ],
   "source": [
    "# Define alpha values to test (regularization strength)\n",
    "alpha_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "# Initialize Lasso with GridSearch for hyperparameter tuning\n",
    "lasso_grid = GridSearchCV(\n",
    "    Lasso(random_state=42, max_iter=2000),\n",
    "    param_grid={'alpha': alpha_values},\n",
    "    cv=group_kfold,  # Use GroupKFold to prevent country leakage\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit on training data (using scaled data)\n",
    "lasso_grid.fit(X_train_scaled, y_train, groups=groups_train)\n",
    "\n",
    "# Get the best model\n",
    "lasso_model = lasso_grid.best_estimator_\n",
    "best_alpha = lasso_grid.best_params_['alpha']\n",
    "\n",
    "print(f\"Best alpha (regularization strength): {best_alpha}\")\n",
    "print(f\"Cross-validation score: {-lasso_grid.best_score_:.3f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = lasso_model.predict(X_train_scaled)\n",
    "y_val_pred = lasso_model.predict(X_val_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display results (focus on fit measures)\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: {train_rmse:.3f}\")\n",
    "print(f\"  MAE:  {train_mae:.3f}\")\n",
    "print(f\"  R²:   {train_r2:.3f}\")\n",
    "\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  RMSE: {val_rmse:.3f}\")\n",
    "print(f\"  MAE:  {val_mae:.3f}\")\n",
    "print(f\"  R²:   {val_r2:.3f}\")\n",
    "\n",
    "# Show feature selection results\n",
    "non_zero_features = np.sum(lasso_model.coef_ != 0)\n",
    "print(f\"\\nFeature Selection:\")\n",
    "print(f\"  Features selected: {non_zero_features}/{len(predictor_cols_linear)}\")\n",
    "print(f\"  Features eliminated: {len(predictor_cols_linear) - non_zero_features}\")\n",
    "\n",
    "# Coefficient magnitudes (features are scaled)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': predictor_cols_linear,\n",
    "    'importance': np.abs(lasso_model.coef_)\n",
    "})\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e90b4",
   "metadata": {},
   "source": [
    "### Ridge Regression (L2 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4cb9cea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (regularization strength): 100.0\n",
      "Cross-validation score: 188.759\n",
      "\n",
      "Training Performance:\n",
      "  RMSE: 11.314\n",
      "  MAE:  8.681\n",
      "  R²:   0.505\n",
      "\n",
      "Validation Performance:\n",
      "  RMSE: 12.002\n",
      "  MAE:  9.627\n",
      "  R²:   0.466\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                 feature  importance\n",
      "16            region_eap    9.537322\n",
      "17            region_eca    9.487646\n",
      "21            region_ssa    8.482274\n",
      "18            region_lac    6.349557\n",
      "4        life_exp_female    5.606925\n",
      "1   fertility_adolescent    5.562440\n",
      "8   gdp_per_capita_const    4.960477\n",
      "3       dependency_ratio    4.561144\n",
      "15      income_upper_mid    4.052803\n",
      "13           income_high    4.021346\n"
     ]
    }
   ],
   "source": [
    "# Define alpha values to test (regularization strength)\n",
    "alpha_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "# Initialize Ridge with GridSearch for hyperparameter tuning\n",
    "ridge_grid = GridSearchCV(\n",
    "    Ridge(random_state=42),\n",
    "    param_grid={'alpha': alpha_values},\n",
    "    cv=group_kfold,  # Use GroupKFold to prevent country leakage\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit on training data (using scaled data)\n",
    "ridge_grid.fit(X_train_scaled, y_train, groups=groups_train)\n",
    "\n",
    "# Get the best model\n",
    "ridge_model = ridge_grid.best_estimator_\n",
    "best_alpha = ridge_grid.best_params_['alpha']\n",
    "\n",
    "print(f\"Best alpha (regularization strength): {best_alpha}\")\n",
    "print(f\"Cross-validation score: {-ridge_grid.best_score_:.3f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = ridge_model.predict(X_train_scaled)\n",
    "y_val_pred = ridge_model.predict(X_val_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: {train_rmse:.3f}\")\n",
    "print(f\"  MAE:  {train_mae:.3f}\")\n",
    "print(f\"  R²:   {train_r2:.3f}\")\n",
    "\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  RMSE: {val_rmse:.3f}\")\n",
    "print(f\"  MAE:  {val_mae:.3f}\")\n",
    "print(f\"  R²:   {val_r2:.3f}\")\n",
    "\n",
    "# Feature importance for Ridge (coefficient magnitudes)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': predictor_cols_linear,\n",
    "    'importance': np.abs(ridge_model.coef_)\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0014ce56",
   "metadata": {},
   "source": [
    "### Elastic Net Regression (L1+L2 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f43b07fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Elastic Net with hyperparameter tuning...\n",
      "Best hyperparameters:\n",
      "  alpha: 0.1\n",
      "  l1_ratio: 0.7\n",
      "Cross-validation score: 188.273\n",
      "\n",
      "Training Performance:\n",
      "  RMSE: 11.364\n",
      "  MAE:  8.715\n",
      "  R²:   0.500\n",
      "\n",
      "Validation Performance:\n",
      "  RMSE: 11.945\n",
      "  MAE:  9.571\n",
      "  R²:   0.471\n",
      "\n",
      "Top 10 features by |coefficient|:\n",
      "                 feature      coef  abs_coef\n",
      "17            region_eca  9.550699  9.550699\n",
      "16            region_eap  9.487653  9.487653\n",
      "21            region_ssa  8.562177  8.562177\n",
      "18            region_lac  6.379608  6.379608\n",
      "1   fertility_adolescent  5.172243  5.172243\n",
      "4        life_exp_female -5.060523  5.060523\n",
      "8   gdp_per_capita_const  4.683260  4.683260\n",
      "3       dependency_ratio -4.455061  4.455061\n",
      "15      income_upper_mid -3.672179  3.672179\n",
      "13           income_high -3.506394  3.506394\n"
     ]
    }
   ],
   "source": [
    "# Define grids for Elastic Net\n",
    "alpha_values = [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "l1_ratios = [0.1, 0.3, 0.5, 0.7, 0.9]  # 0 → pure Ridge, 1 → pure Lasso\n",
    "\n",
    "elastic_grid = GridSearchCV(\n",
    "    ElasticNet(max_iter=5000, random_state=42),\n",
    "    param_grid={'alpha': alpha_values, 'l1_ratio': l1_ratios},\n",
    "    cv=group_kfold,                 # same GroupKFold by country\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Fitting Elastic Net with hyperparameter tuning...\")\n",
    "elastic_grid.fit(X_train_scaled, y_train, groups=groups_train)\n",
    "\n",
    "elastic_model = elastic_grid.best_estimator_\n",
    "best_params = elastic_grid.best_params_\n",
    "\n",
    "print(f\"Best hyperparameters:\")\n",
    "print(f\"  alpha: {best_params['alpha']}\")\n",
    "print(f\"  l1_ratio: {best_params['l1_ratio']}\")\n",
    "print(f\"Cross-validation score: {-elastic_grid.best_score_:.3f}\")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = elastic_model.predict(X_train_scaled)\n",
    "y_val_pred = elastic_model.predict(X_val_scaled)\n",
    "\n",
    "# Metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: {train_rmse:.3f}\")\n",
    "print(f\"  MAE:  {train_mae:.3f}\")\n",
    "print(f\"  R²:   {train_r2:.3f}\")\n",
    "\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  RMSE: {val_rmse:.3f}\")\n",
    "print(f\"  MAE:  {val_mae:.3f}\")\n",
    "print(f\"  R²:   {val_r2:.3f}\")\n",
    "\n",
    "# Coefficient magnitudes\n",
    "coef_importance = pd.DataFrame({\n",
    "    'feature': predictor_cols_linear,\n",
    "    'coef': elastic_model.coef_,\n",
    "    'abs_coef': np.abs(elastic_model.coef_)\n",
    "}).sort_values('abs_coef', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 features by |coefficient|:\")\n",
    "print(coef_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a010fb1",
   "metadata": {},
   "source": [
    "## Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "55bc9619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SVR (RBF) with more regularized hyperparameter grid...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best hyperparameters:\n",
      "  C (regularization): 10\n",
      "  Gamma (kernel coef): scale\n",
      "  Epsilon (tolerance): 0.5\n",
      "Cross-validation score: 180.817\n",
      "\n",
      "Training Performance:\n",
      "  RMSE: 5.711\n",
      "  MAE:  3.286\n",
      "  R²:   0.874\n",
      "\n",
      "Validation Performance:\n",
      "  RMSE: 11.103\n",
      "  MAE:  8.636\n",
      "  R²:   0.543\n",
      "\n",
      "Model Characteristics:\n",
      "  Kernel: RBF (Radial Basis Function)\n",
      "  Support vectors: [2196]\n",
      "  Non-linear decision boundary\n"
     ]
    }
   ],
   "source": [
    "# Set simpler, regularized grid\n",
    "param_grid = {\n",
    "    # slightly favor smaller C (stronger regularization)\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    # a bit wider epsilon range (flatter function, less overfit)\n",
    "    'epsilon': [0.05, 0.1, 0.2, 0.5],\n",
    "    # avoid very small fixed gamma that can lead to overfitting\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svr_grid = GridSearchCV(\n",
    "    SVR(kernel='rbf'),\n",
    "    param_grid=param_grid,\n",
    "    cv=group_kfold,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Fitting SVR (RBF) with more regularized hyperparameter grid...\")\n",
    "svr_grid.fit(X_train_scaled, y_train, groups=groups_train)\n",
    "svr_model = svr_grid.best_estimator_\n",
    "best_params = svr_grid.best_params_\n",
    "\n",
    "print(f\"Best hyperparameters:\")\n",
    "print(f\"  C (regularization): {best_params['C']}\")\n",
    "print(f\"  Gamma (kernel coef): {best_params['gamma']}\")\n",
    "print(f\"  Epsilon (tolerance): {best_params['epsilon']}\")\n",
    "print(f\"Cross-validation score: {-svr_grid.best_score_:.3f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = svr_model.predict(X_train_scaled)\n",
    "y_val_pred = svr_model.predict(X_val_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: {train_rmse:.3f}\")\n",
    "print(f\"  MAE:  {train_mae:.3f}\")\n",
    "print(f\"  R²:   {train_r2:.3f}\")\n",
    "\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  RMSE: {val_rmse:.3f}\")\n",
    "print(f\"  MAE:  {val_mae:.3f}\")\n",
    "print(f\"  R²:   {val_r2:.3f}\")\n",
    "\n",
    "print(f\"\\nModel Characteristics:\")\n",
    "print(f\"  Kernel: RBF (Radial Basis Function)\")\n",
    "print(f\"  Support vectors: {svr_model.n_support_}\")\n",
    "print(f\"  Non-linear decision boundary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bcb27b",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Regression (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3cff9f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting KNN with hyperparameter tuning...\n",
      "Best hyperparameters:\n",
      "  n_neighbors: 20\n",
      "  weights: distance\n",
      "  metric: euclidean\n",
      "Cross-validation score: 208.827\n",
      "\n",
      "Training Performance:\n",
      "  RMSE: 0.000\n",
      "  MAE:  0.000\n",
      "  R²:   1.000\n",
      "\n",
      "Validation Performance:\n",
      "  RMSE: 13.788\n",
      "  MAE:  10.402\n",
      "  R²:   0.295\n",
      "\n",
      "Model Characteristics:\n",
      "  Non-parametric model\n",
      "  Memory-based learning\n",
      "  Local predictions based on nearest neighbors\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters to test\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 10, 15, 20],     # Number of neighbors\n",
    "    'weights': ['uniform', 'distance'],        # Weighting scheme\n",
    "    'metric': ['euclidean', 'manhattan']       # Distance metric\n",
    "}\n",
    "\n",
    "# Initialize KNN with GridSearch for hyperparameter tuning\n",
    "knn_grid = GridSearchCV(\n",
    "    KNeighborsRegressor(),\n",
    "    param_grid=param_grid,\n",
    "    cv=group_kfold,  # Use GroupKFold to prevent country leakage\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Fitting KNN with hyperparameter tuning...\")\n",
    "\n",
    "# Fit on training data (using scaled data - KNN needs scaling!)\n",
    "knn_grid.fit(X_train_scaled, y_train, groups=groups_train)\n",
    "\n",
    "# Get the best model\n",
    "knn_model = knn_grid.best_estimator_\n",
    "best_params = knn_grid.best_params_\n",
    "\n",
    "print(f\"Best hyperparameters:\")\n",
    "print(f\"  n_neighbors: {best_params['n_neighbors']}\")\n",
    "print(f\"  weights: {best_params['weights']}\")\n",
    "print(f\"  metric: {best_params['metric']}\")\n",
    "print(f\"Cross-validation score: {-knn_grid.best_score_:.3f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = knn_model.predict(X_train_scaled)\n",
    "y_val_pred = knn_model.predict(X_val_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: {train_rmse:.3f}\")\n",
    "print(f\"  MAE:  {train_mae:.3f}\")\n",
    "print(f\"  R²:   {train_r2:.3f}\")\n",
    "\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  RMSE: {val_rmse:.3f}\")\n",
    "print(f\"  MAE:  {val_mae:.3f}\")\n",
    "print(f\"  R²:   {val_r2:.3f}\")\n",
    "\n",
    "print(f\"\\nModel Characteristics:\")\n",
    "print(f\"  Non-parametric model\")\n",
    "print(f\"  Memory-based learning\")\n",
    "print(f\"  Local predictions based on nearest neighbors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d0e13",
   "metadata": {},
   "source": [
    "## Tree-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371344a",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2db99",
   "metadata": {},
   "source": [
    "**Note**: Using reduced hyperparameter grids for initial model comparison. These smaller grids provide sufficient exploration to compare algorithm performance while keeping runtime manageable. Full hyperparameter optimization can be done later for the best-performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dce672fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random Forest with hyperparameter tuning...\n",
      "This may take several minutes...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best hyperparameters:\n",
      "  n_estimators: 100\n",
      "  max_depth: 10\n",
      "  min_samples_split: 5\n",
      "  min_samples_leaf: 2\n",
      "  max_features: sqrt\n",
      "Cross-validation score: 227.948\n",
      "\n",
      "Training Performance:\n",
      "  RMSE: 4.208\n",
      "  MAE:  3.098\n",
      "  R²:   0.931\n",
      "\n",
      "Validation Performance:\n",
      "  RMSE: 13.403\n",
      "  MAE:  10.706\n",
      "  R²:   0.333\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                 feature  importance\n",
      "7    secondary_enroll_fe    0.110851\n",
      "8   gdp_per_capita_const    0.088424\n",
      "6       population_total    0.084224\n",
      "1   fertility_adolescent    0.081178\n",
      "2       urban_population    0.080515\n",
      "12           rule_of_law    0.077093\n",
      "11          industry_gdp    0.073440\n",
      "4        life_exp_female    0.070600\n",
      "0         fertility_rate    0.067408\n",
      "3       dependency_ratio    0.047004\n"
     ]
    }
   ],
   "source": [
    "# Note that we use the imputed but unscaled data for Random Forest\n",
    "\n",
    "# Define hyperparameters to test (reduced grid for initial comparison)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],               # Number of trees\n",
    "    'max_depth': [10, None],                  # Maximum tree depth\n",
    "    'min_samples_split': [2, 5],              # Min samples to split node\n",
    "    'min_samples_leaf': [1, 2],               # Min samples in leaf\n",
    "    'max_features': ['sqrt', 0.3]             # Features per split\n",
    "}\n",
    "\n",
    "# Initialize Random Forest with GridSearch for hyperparameter tuning\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    param_grid=param_grid,\n",
    "    cv=group_kfold,  # Use GroupKFold to prevent country leakage\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1  # Show progress\n",
    ")\n",
    "\n",
    "print(\"Fitting Random Forest with hyperparameter tuning...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "# Fit on training data (using imputed but unscaled data)\n",
    "rf_grid.fit(X_train_imputed, y_train, groups=groups_train)\n",
    "\n",
    "# Get the best model\n",
    "rf_model = rf_grid.best_estimator_\n",
    "best_params = rf_grid.best_params_\n",
    "\n",
    "print(f\"Best hyperparameters:\")\n",
    "print(f\"  n_estimators: {best_params['n_estimators']}\")\n",
    "print(f\"  max_depth: {best_params['max_depth']}\")\n",
    "print(f\"  min_samples_split: {best_params['min_samples_split']}\")\n",
    "print(f\"  min_samples_leaf: {best_params['min_samples_leaf']}\")\n",
    "print(f\"  max_features: {best_params['max_features']}\")\n",
    "print(f\"Cross-validation score: {-rf_grid.best_score_:.3f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = rf_model.predict(X_train_imputed)\n",
    "y_val_pred = rf_model.predict(X_val_imputed)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: {train_rmse:.3f}\")\n",
    "print(f\"  MAE:  {train_mae:.3f}\")\n",
    "print(f\"  R²:   {train_r2:.3f}\")\n",
    "\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  RMSE: {val_rmse:.3f}\")\n",
    "print(f\"  MAE:  {val_mae:.3f}\")\n",
    "print(f\"  R²:   {val_r2:.3f}\")\n",
    "\n",
    "# Save feature importance for model interpretation and comparison\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': predictor_cols_tree,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf36e43",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2cf983ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting XGBoost with hyperparameter tuning...\n",
      "This may take several minutes...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best hyperparameters:\n",
      "  n_estimators: 100\n",
      "  max_depth: 6\n",
      "  learning_rate: 0.01\n",
      "  subsample: 0.9\n",
      "  colsample_bytree: 0.9\n",
      "Cross-validation score: 233.876\n",
      "\n",
      "Training Performance:\n",
      "  RMSE: 9.777\n",
      "  MAE:  7.546\n",
      "  R²:   0.630\n",
      "\n",
      "Validation Performance:\n",
      "  RMSE: 13.889\n",
      "  MAE:  11.178\n",
      "  R²:   0.284\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                 feature  importance\n",
      "14            region_eap    0.095663\n",
      "15            region_eca    0.095188\n",
      "11          industry_gdp    0.090066\n",
      "16            region_lac    0.081232\n",
      "19            region_ssa    0.080724\n",
      "13  income_level_encoded    0.072680\n",
      "8   gdp_per_capita_const    0.064802\n",
      "4        life_exp_female    0.063589\n",
      "12           rule_of_law    0.059961\n",
      "10          services_gdp    0.059404\n"
     ]
    }
   ],
   "source": [
    "# Note that we use the raw unimputed data for XGBoost because it can handle missing values natively\n",
    "\n",
    "# Clean column names to snake_case for consistency\n",
    "X_train_raw_xgb = X_train_raw.copy()\n",
    "X_val_raw_xgb = X_val_raw.copy()\n",
    "X_test_raw_xgb = X_test_raw.copy()\n",
    "\n",
    "# Convert to snake_case: lowercase, replace special chars and spaces with underscores\n",
    "X_train_raw_xgb.columns = (X_train_raw_xgb.columns\n",
    "                            .str.lower()\n",
    "                            .str.replace('[^a-z0-9]+', '_', regex=True)\n",
    "                            .str.strip('_'))\n",
    "X_val_raw_xgb.columns = (X_val_raw_xgb.columns\n",
    "                          .str.lower()\n",
    "                          .str.replace('[^a-z0-9]+', '_', regex=True)\n",
    "                          .str.strip('_'))\n",
    "X_test_raw_xgb.columns = (X_test_raw_xgb.columns\n",
    "                           .str.lower()\n",
    "                           .str.replace('[^a-z0-9]+', '_', regex=True)\n",
    "                           .str.strip('_'))\n",
    "\n",
    "# Define hyperparameters to test (reduced grid for initial comparison)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],               # Number of boosting rounds\n",
    "    'max_depth': [3, 6],                      # Maximum tree depth\n",
    "    'learning_rate': [0.01, 0.1],             # Step size shrinkage\n",
    "    'subsample': [0.9, 1.0],                  # Fraction of samples per tree\n",
    "    'colsample_bytree': [0.9, 1.0]            # Fraction of features per tree\n",
    "}\n",
    "\n",
    "# Initialize XGBoost with GridSearch for hyperparameter tuning\n",
    "xgb_grid = GridSearchCV(\n",
    "    xgb.XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    param_grid=param_grid,\n",
    "    cv=group_kfold,  # Use GroupKFold to prevent country leakage\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1  # Show progress\n",
    ")\n",
    "\n",
    "print(\"Fitting XGBoost with hyperparameter tuning...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "# Fit on cleaned training data\n",
    "xgb_grid.fit(X_train_raw_xgb, y_train, groups=groups_train)\n",
    "\n",
    "# Get the best model\n",
    "xgb_model = xgb_grid.best_estimator_\n",
    "best_params = xgb_grid.best_params_\n",
    "\n",
    "print(f\"Best hyperparameters:\")\n",
    "print(f\"  n_estimators: {best_params['n_estimators']}\")\n",
    "print(f\"  max_depth: {best_params['max_depth']}\")\n",
    "print(f\"  learning_rate: {best_params['learning_rate']}\")\n",
    "print(f\"  subsample: {best_params['subsample']}\")\n",
    "print(f\"  colsample_bytree: {best_params['colsample_bytree']}\")\n",
    "print(f\"Cross-validation score: {-xgb_grid.best_score_:.3f}\")\n",
    "\n",
    "# Make predictions using cleaned data\n",
    "y_train_pred = xgb_model.predict(X_train_raw_xgb)\n",
    "y_val_pred = xgb_model.predict(X_val_raw_xgb)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: {train_rmse:.3f}\")\n",
    "print(f\"  MAE:  {train_mae:.3f}\")\n",
    "print(f\"  R²:   {train_r2:.3f}\")\n",
    "\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  RMSE: {val_rmse:.3f}\")\n",
    "print(f\"  MAE:  {val_mae:.3f}\")\n",
    "print(f\"  R²:   {val_r2:.3f}\")\n",
    "\n",
    "# Feature importance for XGBoost\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': predictor_cols_tree,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c119f6",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c5200fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LightGBM with hyperparameter tuning...\n",
      "This may take several minutes...\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best hyperparameters:\n",
      "  n_estimators: 100\n",
      "  max_depth: 6\n",
      "  learning_rate: 0.01\n",
      "  subsample: 0.9\n",
      "  colsample_bytree: 0.9\n",
      "  num_leaves: 50\n",
      "Cross-validation score: 233.796\n",
      "\n",
      "Training Performance:\n",
      "  RMSE: 9.932\n",
      "  MAE:  7.662\n",
      "  R²:   0.618\n",
      "\n",
      "Validation Performance:\n",
      "  RMSE: 14.503\n",
      "  MAE:  11.536\n",
      "  R²:   0.220\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                 feature  importance\n",
      "6       population_total         441\n",
      "2       urban_population         269\n",
      "8   gdp_per_capita_const         263\n",
      "12           rule_of_law         249\n",
      "4        life_exp_female         210\n",
      "0         fertility_rate         203\n",
      "5       infant_mortality         186\n",
      "1   fertility_adolescent         180\n",
      "13  income_level_encoded         170\n",
      "11          industry_gdp         147\n"
     ]
    }
   ],
   "source": [
    "# Note that we use the raw unimputed data for LightGBM because it can handle missing values natively\n",
    "\n",
    "# IMPORTANT: Clean column names for LightGBM (it doesn't support special characters)\n",
    "# Convert to snake_case for consistency\n",
    "X_train_raw_lgb = X_train_raw.copy()\n",
    "X_val_raw_lgb = X_val_raw.copy()\n",
    "X_test_raw_lgb = X_test_raw.copy()\n",
    "\n",
    "# Convert to snake_case: lowercase, replace special chars and spaces with underscores\n",
    "X_train_raw_lgb.columns = (X_train_raw_lgb.columns\n",
    "                            .str.lower()\n",
    "                            .str.replace('[^a-z0-9]+', '_', regex=True)\n",
    "                            .str.strip('_'))\n",
    "X_val_raw_lgb.columns = (X_val_raw_lgb.columns\n",
    "                          .str.lower()\n",
    "                          .str.replace('[^a-z0-9]+', '_', regex=True)\n",
    "                          .str.strip('_'))\n",
    "X_test_raw_lgb.columns = (X_test_raw_lgb.columns\n",
    "                           .str.lower()\n",
    "                           .str.replace('[^a-z0-9]+', '_', regex=True)\n",
    "                           .str.strip('_'))\n",
    "\n",
    "# Define hyperparameters to test (reduced grid for initial comparison)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],               # Number of boosting rounds\n",
    "    'max_depth': [3, 6],                      # Maximum tree depth\n",
    "    'learning_rate': [0.01, 0.1],             # Step size shrinkage\n",
    "    'subsample': [0.9, 1.0],                  # Fraction of samples per tree\n",
    "    'colsample_bytree': [0.9, 1.0],           # Fraction of features per tree\n",
    "    'num_leaves': [31, 50]                    # Maximum number of leaves per tree\n",
    "}\n",
    "\n",
    "# Initialize LightGBM with GridSearch for hyperparameter tuning\n",
    "lgb_grid = GridSearchCV(\n",
    "    lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1),\n",
    "    param_grid=param_grid,\n",
    "    cv=group_kfold,  # Use GroupKFold to prevent country leakage\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1  # Show progress\n",
    ")\n",
    "\n",
    "print(\"Fitting LightGBM with hyperparameter tuning...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "# Fit on cleaned training data\n",
    "lgb_grid.fit(X_train_raw_lgb, y_train, groups=groups_train)\n",
    "\n",
    "# Get the best model\n",
    "lgb_model = lgb_grid.best_estimator_\n",
    "best_params = lgb_grid.best_params_\n",
    "\n",
    "print(f\"Best hyperparameters:\")\n",
    "print(f\"  n_estimators: {best_params['n_estimators']}\")\n",
    "print(f\"  max_depth: {best_params['max_depth']}\")\n",
    "print(f\"  learning_rate: {best_params['learning_rate']}\")\n",
    "print(f\"  subsample: {best_params['subsample']}\")\n",
    "print(f\"  colsample_bytree: {best_params['colsample_bytree']}\")\n",
    "print(f\"  num_leaves: {best_params['num_leaves']}\")\n",
    "print(f\"Cross-validation score: {-lgb_grid.best_score_:.3f}\")\n",
    "\n",
    "# Make predictions using cleaned data\n",
    "y_train_pred = lgb_model.predict(X_train_raw_lgb)\n",
    "y_val_pred = lgb_model.predict(X_val_raw_lgb)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: {train_rmse:.3f}\")\n",
    "print(f\"  MAE:  {train_mae:.3f}\")\n",
    "print(f\"  R²:   {train_r2:.3f}\")\n",
    "\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  RMSE: {val_rmse:.3f}\")\n",
    "print(f\"  MAE:  {val_mae:.3f}\")\n",
    "print(f\"  R²:   {val_r2:.3f}\")\n",
    "\n",
    "# Feature importance for LightGBM\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': predictor_cols_tree,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997e6c3",
   "metadata": {},
   "source": [
    "### CatBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9fb406db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CatBoost with hyperparameter tuning...\n",
      "This may take several minutes...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best hyperparameters:\n",
      "  iterations: 200\n",
      "  depth: 6\n",
      "  learning_rate: 0.01\n",
      "  l2_leaf_reg: 5\n",
      "Cross-validation score: 230.037\n",
      "\n",
      "Training Performance:\n",
      "  RMSE: 10.078\n",
      "  MAE:  7.767\n",
      "  R²:   0.607\n",
      "\n",
      "Validation Performance:\n",
      "  RMSE: 13.436\n",
      "  MAE:  10.844\n",
      "  R²:   0.330\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                 feature  importance\n",
      "2       urban_population   12.195206\n",
      "6       population_total   11.550263\n",
      "1   fertility_adolescent    9.980830\n",
      "13  income_level_encoded    9.464382\n",
      "19            region_ssa    7.868200\n",
      "11          industry_gdp    6.824441\n",
      "10          services_gdp    6.376157\n",
      "8   gdp_per_capita_const    6.018800\n",
      "14            region_eap    5.950609\n",
      "4        life_exp_female    5.287192\n"
     ]
    }
   ],
   "source": [
    "# Note that we use the raw unimputed data for CatBoost because it can handle missing values natively\n",
    "\n",
    "# Clean column names to snake_case for consistency\n",
    "X_train_raw_cat = X_train_raw.copy()\n",
    "X_val_raw_cat = X_val_raw.copy()\n",
    "X_test_raw_cat = X_test_raw.copy()\n",
    "\n",
    "# Convert to snake_case: lowercase, replace special chars and spaces with underscores\n",
    "X_train_raw_cat.columns = (X_train_raw_cat.columns\n",
    "                            .str.lower()\n",
    "                            .str.replace('[^a-z0-9]+', '_', regex=True)\n",
    "                            .str.strip('_'))\n",
    "X_val_raw_cat.columns = (X_val_raw_cat.columns\n",
    "                          .str.lower()\n",
    "                          .str.replace('[^a-z0-9]+', '_', regex=True)\n",
    "                          .str.strip('_'))\n",
    "X_test_raw_cat.columns = (X_test_raw_cat.columns\n",
    "                           .str.lower()\n",
    "                           .str.replace('[^a-z0-9]+', '_', regex=True)\n",
    "                           .str.strip('_'))\n",
    "\n",
    "# Define hyperparameters to test (reduced grid for initial comparison)\n",
    "param_grid = {\n",
    "    'iterations': [100, 200],                 # Number of boosting rounds\n",
    "    'depth': [3, 6],                          # Maximum tree depth\n",
    "    'learning_rate': [0.01, 0.1],             # Step size shrinkage\n",
    "    'l2_leaf_reg': [1, 3, 5]                  # L2 regularization\n",
    "}\n",
    "\n",
    "# Initialize CatBoost with GridSearch for hyperparameter tuning\n",
    "catboost_grid = GridSearchCV(\n",
    "    CatBoostRegressor(random_state=42, verbose=0),\n",
    "    param_grid=param_grid,\n",
    "    cv=group_kfold,  # Use GroupKFold to prevent country leakage\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1  # Show progress\n",
    ")\n",
    "\n",
    "print(\"Fitting CatBoost with hyperparameter tuning...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "# Fit on cleaned training data\n",
    "catboost_grid.fit(X_train_raw_cat, y_train, groups=groups_train)\n",
    "\n",
    "# Get the best model\n",
    "catboost_model = catboost_grid.best_estimator_\n",
    "best_params = catboost_grid.best_params_\n",
    "\n",
    "print(f\"Best hyperparameters:\")\n",
    "print(f\"  iterations: {best_params['iterations']}\")\n",
    "print(f\"  depth: {best_params['depth']}\")\n",
    "print(f\"  learning_rate: {best_params['learning_rate']}\")\n",
    "print(f\"  l2_leaf_reg: {best_params['l2_leaf_reg']}\")\n",
    "print(f\"Cross-validation score: {-catboost_grid.best_score_:.3f}\")\n",
    "\n",
    "# Make predictions using cleaned data\n",
    "y_train_pred = catboost_model.predict(X_train_raw_cat)\n",
    "y_val_pred = catboost_model.predict(X_val_raw_cat)\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: {train_rmse:.3f}\")\n",
    "print(f\"  MAE:  {train_mae:.3f}\")\n",
    "print(f\"  R²:   {train_r2:.3f}\")\n",
    "\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  RMSE: {val_rmse:.3f}\")\n",
    "print(f\"  MAE:  {val_mae:.3f}\")\n",
    "print(f\"  R²:   {val_r2:.3f}\")\n",
    "\n",
    "# Feature importance for CatBoost\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': predictor_cols_tree,\n",
    "    'importance': catboost_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd0d86",
   "metadata": {},
   "source": [
    "## Ensemble (ElasticNet + SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99db8a1",
   "metadata": {},
   "source": [
    "### Try with 50/50 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "39c8959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble (Elastic Net + SVR) - Training Performance:\n",
      "  RMSE: 7.826\n",
      "  MAE:  5.733\n",
      "  R²:   0.763\n",
      "\n",
      "Ensemble (Elastic Net + SVR) - Validation Performance:\n",
      "  RMSE: 10.826\n",
      "  MAE:  8.382\n",
      "  R²:   0.565\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Individual model predictions\n",
    "y_train_pred_elastic = elastic_model.predict(X_train_scaled)\n",
    "y_val_pred_elastic   = elastic_model.predict(X_val_scaled)\n",
    "\n",
    "y_train_pred_svr = svr_model.predict(X_train_scaled)\n",
    "y_val_pred_svr   = svr_model.predict(X_val_scaled)\n",
    "\n",
    "# Simple equal-weight average ensemble\n",
    "w_elastic = 0.5\n",
    "w_svr = 0.5\n",
    "\n",
    "y_train_pred_ens = w_elastic * y_train_pred_elastic + w_svr * y_train_pred_svr\n",
    "y_val_pred_ens   = w_elastic * y_val_pred_elastic   + w_svr * y_val_pred_svr\n",
    "\n",
    "# Metrics: train\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_ens))\n",
    "train_mae  = mean_absolute_error(y_train, y_train_pred_ens)\n",
    "train_r2   = r2_score(y_train, y_train_pred_ens)\n",
    "\n",
    "# Metrics: validation\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_ens))\n",
    "val_mae  = mean_absolute_error(y_val, y_val_pred_ens)\n",
    "val_r2   = r2_score(y_val, y_val_pred_ens)\n",
    "\n",
    "print(\"\\nEnsemble (Elastic Net + SVR) - Training Performance:\")\n",
    "print(f\"  RMSE: {train_rmse:.3f}\")\n",
    "print(f\"  MAE:  {train_mae:.3f}\")\n",
    "print(f\"  R²:   {train_r2:.3f}\")\n",
    "\n",
    "print(\"\\nEnsemble (Elastic Net + SVR) - Validation Performance:\")\n",
    "print(f\"  RMSE: {val_rmse:.3f}\")\n",
    "print(f\"  MAE:  {val_mae:.3f}\")\n",
    "print(f\"  R²:   {val_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eeb013",
   "metadata": {},
   "source": [
    "### Try tuning weights in a small grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "66312a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weight on Elastic Net (1-w on SVR): w = 0.35\n",
      "Validation RMSE: 10.756, MAE: 8.351, R²: 0.571\n"
     ]
    }
   ],
   "source": [
    "# Precomputed single-model preds\n",
    "y_val_pred_elastic = elastic_model.predict(X_val_scaled)\n",
    "y_val_pred_svr     = svr_model.predict(X_val_scaled)\n",
    "\n",
    "best_w = None\n",
    "best_r2 = -np.inf\n",
    "best_stats = None\n",
    "\n",
    "for w in np.linspace(0.0, 1.0, 21):  # 0.0, 0.05, ..., 1.0\n",
    "    y_val_pred_ens = w * y_val_pred_elastic + (1 - w) * y_val_pred_svr\n",
    "    r2  = r2_score(y_val, y_val_pred_ens)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_ens))\n",
    "    mae  = mean_absolute_error(y_val, y_val_pred_ens)\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_w = w\n",
    "        best_stats = (rmse, mae, r2)\n",
    "\n",
    "print(f\"Best weight on Elastic Net (1-w on SVR): w = {best_w:.2f}\")\n",
    "print(f\"Validation RMSE: {best_stats[0]:.3f}, MAE: {best_stats[1]:.3f}, R²: {best_stats[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8302b1",
   "metadata": {},
   "source": [
    "## Model Comparison on the Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af44cda",
   "metadata": {},
   "source": [
    "The table below summarizes validation performance for all candidate models on the country‑held‑out split, using the final, regularized RBF SVR grid (and omitting the linear‑kernel SVR). Metrics are RMSE, MAE, and R² on the validation set of unseen countries; lower RMSE/MAE and higher R² are better.\n",
    "\n",
    "| **Model**            | **RMSE (val)** | **MAE (val)** | **R² (val)** |\n",
    "|----------------------|----------------|----------------|--------------|\n",
    "| OLS                  | 12.045         | 9.660          | 0.462        |\n",
    "| Lasso                | 11.818         | 9.355          | 0.482        |\n",
    "| Ridge                | 12.002         | 9.627          | 0.466        |\n",
    "| Elastic Net          | 11.945         | 9.571          | 0.471        |\n",
    "| SVR (RBF, tuned)     | 11.103         | 8.636          | 0.543        |\n",
    "| KNN                  | 13.788         | 10.402         | 0.295        |\n",
    "| Random Forest        | 13.403         | 10.706         | 0.333        |\n",
    "| XGBoost              | 13.889         | 11.178         | 0.284        |\n",
    "| LightGBM             | 14.503         | 11.536         | 0.220        |\n",
    "| CatBoost             | 13.436         | 10.844         | 0.330        |\n",
    "| **Ensemble (EN+SVR)**| **10.756**     | **8.351**      | **0.571**    |\n",
    "\n",
    "Across the linear family, Lasso, Ridge, and Elastic Net all perform similarly, with validation R² in the 0.47–0.48 range and regularization smoothing out noise while preserving the main signal. The updated RBF SVR clearly outperforms these linear baselines (R² around 0.543), indicating that there is meaningful non‑linearity in the relationship between the predictors and FLFP that a flexible kernel can exploit. In contrast, KNN and all of the tree/boosting methods (Random Forest, XGBoost, LightGBM, CatBoost) achieve noticeably worse validation R² despite very strong training fits, which is consistent with overfitting country‑specific idiosyncrasies and failing to generalize to entirely new countries under the GroupKFold/country‑split evaluation.\n",
    "\n",
    "Given this pattern, we treated SVR and Elastic Net as the two “good” and complementary models: SVR offering the strongest predictive accuracy, and Elastic Net offering a stable, interpretable linear structure. Rather than choosing a single winner, we constructed a simple ensemble that linearly combines their predictions and tuned the weight on Elastic Net using the validation set. Starting from a 50/50 mix (which already improved on both individual models), we searched over weights and found that giving 35 percent weight to Elastic Net and 65 percent to SVR yielded the best validation performance (RMSE about 10.756, R² about 0.571). This ensemble thus becomes the final model: it leverages the higher accuracy of SVR while tempering its extremes with the more conservative Elastic Net, improving generalization to new countries and aligning with the app’s goal of generating plausible predictions for hypothetical “slider‑defined” countries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5844cf64",
   "metadata": {},
   "source": [
    "## Test Set Evaluation\n",
    "\n",
    "We now evaluate all top-performing models on the held-out test set to assess their final generalization performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "975e9acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ensemble (EN+SVR)</td>\n",
       "      <td>9.730482</td>\n",
       "      <td>7.830651</td>\n",
       "      <td>0.439785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVR</td>\n",
       "      <td>9.833719</td>\n",
       "      <td>7.981249</td>\n",
       "      <td>0.427835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>11.648389</td>\n",
       "      <td>8.983109</td>\n",
       "      <td>0.197181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>11.808271</td>\n",
       "      <td>9.097965</td>\n",
       "      <td>0.174991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>12.412268</td>\n",
       "      <td>9.373027</td>\n",
       "      <td>0.088434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>13.278586</td>\n",
       "      <td>9.947627</td>\n",
       "      <td>-0.043253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model       RMSE       MAE        R²\n",
       "5  Ensemble (EN+SVR)   9.730482  7.830651  0.439785\n",
       "4                SVR   9.833719  7.981249  0.427835\n",
       "3        Elastic Net  11.648389  8.983109  0.197181\n",
       "2              Ridge  11.808271  9.097965  0.174991\n",
       "1              Lasso  12.412268  9.373027  0.088434\n",
       "0                OLS  13.278586  9.947627 -0.043253"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions from all top models on test set\n",
    "test_results = []\n",
    "\n",
    "# OLS\n",
    "y_test_pred_ols = ols_model.predict(X_test_scaled)\n",
    "test_results.append({\n",
    "    'Model': 'OLS',\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred_ols)),\n",
    "    'MAE': mean_absolute_error(y_test, y_test_pred_ols),\n",
    "    'R²': r2_score(y_test, y_test_pred_ols)\n",
    "})\n",
    "\n",
    "# Lasso\n",
    "y_test_pred_lasso = lasso_model.predict(X_test_scaled)\n",
    "test_results.append({\n",
    "    'Model': 'Lasso',\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred_lasso)),\n",
    "    'MAE': mean_absolute_error(y_test, y_test_pred_lasso),\n",
    "    'R²': r2_score(y_test, y_test_pred_lasso)\n",
    "})\n",
    "\n",
    "# Ridge\n",
    "y_test_pred_ridge = ridge_model.predict(X_test_scaled)\n",
    "test_results.append({\n",
    "    'Model': 'Ridge',\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred_ridge)),\n",
    "    'MAE': mean_absolute_error(y_test, y_test_pred_ridge),\n",
    "    'R²': r2_score(y_test, y_test_pred_ridge)\n",
    "})\n",
    "\n",
    "# Elastic Net\n",
    "y_test_pred_elastic = elastic_model.predict(X_test_scaled)\n",
    "test_results.append({\n",
    "    'Model': 'Elastic Net',\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred_elastic)),\n",
    "    'MAE': mean_absolute_error(y_test, y_test_pred_elastic),\n",
    "    'R²': r2_score(y_test, y_test_pred_elastic)\n",
    "})\n",
    "\n",
    "# SVR\n",
    "y_test_pred_svr = svr_model.predict(X_test_scaled)\n",
    "test_results.append({\n",
    "    'Model': 'SVR',\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred_svr)),\n",
    "    'MAE': mean_absolute_error(y_test, y_test_pred_svr),\n",
    "    'R²': r2_score(y_test, y_test_pred_svr)\n",
    "})\n",
    "\n",
    "# Ensemble (35% Elastic Net + 65% SVR)\n",
    "w_elastic = 0.35\n",
    "w_svr = 0.65\n",
    "y_test_pred_ens = w_elastic * y_test_pred_elastic + w_svr * y_test_pred_svr\n",
    "test_results.append({\n",
    "    'Model': 'Ensemble (EN+SVR)',\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred_ens)),\n",
    "    'MAE': mean_absolute_error(y_test, y_test_pred_ens),\n",
    "    'R²': r2_score(y_test, y_test_pred_ens)\n",
    "})\n",
    "\n",
    "# Create DataFrame and sort by R² (descending)\n",
    "test_df_results = pd.DataFrame(test_results).sort_values('R²', ascending=False)\n",
    "\n",
    "print(\"Test Set Performance Comparison:\")\n",
    "display(test_df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3052b6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "On the held-out test set, the Ensemble (35% Elastic Net + 65% SVR) achieves the strongest performance with an R² of 0.440 and RMSE of 9.730, modestly outperforming SVR alone (R² = 0.428, RMSE = 9.834) and substantially outperforming all linear models. While test set performance is notably lower than validation performance across all models (likely reflecting distributional differences between the country splits), the ensemble demonstrates superior robustness: the regularized linear models show severe degradation on the test set (Elastic Net R² drops from 0.471 on validation to 0.197 on test, and OLS even produces negative R²), whereas the ensemble maintains reasonable predictive power. This pattern validates our modeling strategy of combining a flexible non-linear learner (SVR) with a stable linear baseline (Elastic Net)—the ensemble leverages SVR's superior accuracy while tempering its potential overfitting with the more conservative linear structure, resulting in the most reliable predictions for entirely new countries in the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
